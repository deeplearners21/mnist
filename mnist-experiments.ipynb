{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST\n",
    "Here we load the dataset and create data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7cdbbcd22a448983cc89694d639b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6e468a235045119b6915926945d5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba5582ad830450886132e7f5c39aed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb495dcff914af7b4080c11cea4799e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_ds = datasets.MNIST('data', train=True, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "test_ds = datasets.MNIST('data', train=False, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "#batch_size = 5 # for testing\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = iter(train_loader)\n",
    "x, y = next(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking are images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, title=None):\n",
    "    plt.imshow(img, interpolation='none', cmap=\"gray\")\n",
    "    if title is not None: plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first from torch to numpy\n",
    "X = x.numpy(); Y = y.numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(X[0][0], Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the number of neurons in the hidden unit\n",
    "def get_model(M = 300):\n",
    "    net = nn.Sequential(nn.Linear(28*28, M),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(M, 10))\n",
    "    return net #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader, num_epochs, model, optimizer):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            batch = images.shape[0] # size of the batch\n",
    "            # Convert torch tensor to Variable, change shape of the input\n",
    "            images = images.view(-1, 28*28) #.cuda()\n",
    "        \n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()  # zero the gradient buffer\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            total += batch\n",
    "            sum_loss += batch * loss.item()\n",
    "                \n",
    "        train_loss = sum_loss/total\n",
    "        print('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, train_loss))\n",
    "        val_acc, val_loss = model_accuracy_loss(model, test_loader)\n",
    "        print('Epoch [%d/%d], Valid Accuracy: %.4f, Valid Loss: %.4f' %(epoch+1, num_epochs, val_acc, val_loss))\n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy_loss(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, 28*28)  #.cuda()\n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        sum_loss += labels.size(0)*loss.item()\n",
    "        total += labels.size(0)\n",
    "        correct += pred.eq(labels.data).sum().item()\n",
    "    return 100 * correct / total, sum_loss/ total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.71, 2.3597292488098143)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net = get_model()\n",
    "# learning_rate = 0.01\n",
    "# optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "# model_accuracy_loss(net, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1) \n",
    "\n",
    "\n",
    "## The validation accuracy was terrible for learning rates of 1 and 0.1; however, the accuracy shot up to ~90% after lowering the learning rate to 0.01. \n",
    "## The table below shows that the best learning rate is **between 0.001 and 0.0001**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>9.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>11.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>93.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>97.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>98.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>93.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lr  accuracy\n",
       "0  1.00000      9.90\n",
       "1  0.10000     11.36\n",
       "2  0.01000     93.84\n",
       "3  0.00100     97.61\n",
       "4  0.00010     98.07\n",
       "5  0.00001     93.67"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.DataFrame({'lr': learning_rates, 'accuracy': scores})\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 71.5266\n",
      "Epoch [1/10], Valid Accuracy: 10.3600, Valid Loss: 3.5832\n",
      "Epoch [2/10], Loss: 4.0942\n",
      "Epoch [2/10], Valid Accuracy: 11.4400, Valid Loss: 2.4205\n",
      "Epoch [3/10], Loss: 2.4049\n",
      "Epoch [3/10], Valid Accuracy: 10.1800, Valid Loss: 2.3631\n",
      "Epoch [4/10], Loss: 2.4120\n",
      "Epoch [4/10], Valid Accuracy: 10.1900, Valid Loss: 2.4910\n",
      "Epoch [5/10], Loss: 2.4028\n",
      "Epoch [5/10], Valid Accuracy: 10.1800, Valid Loss: 2.4416\n",
      "Epoch [6/10], Loss: 2.4125\n",
      "Epoch [6/10], Valid Accuracy: 10.1900, Valid Loss: 2.3828\n",
      "Epoch [7/10], Loss: 2.4076\n",
      "Epoch [7/10], Valid Accuracy: 9.9000, Valid Loss: 2.4219\n",
      "Epoch [8/10], Loss: 2.4043\n",
      "Epoch [8/10], Valid Accuracy: 11.4400, Valid Loss: 2.4740\n",
      "Epoch [9/10], Loss: 2.4049\n",
      "Epoch [9/10], Valid Accuracy: 9.8100, Valid Loss: 2.3791\n",
      "Epoch [10/10], Loss: 2.4096\n",
      "Epoch [10/10], Valid Accuracy: 9.9000, Valid Loss: 2.4724\n",
      "Epoch [1/10], Loss: 2.8813\n",
      "Epoch [1/10], Valid Accuracy: 13.5700, Valid Loss: 4.9234\n",
      "Epoch [2/10], Loss: 2.2839\n",
      "Epoch [2/10], Valid Accuracy: 12.4900, Valid Loss: 2.2864\n",
      "Epoch [3/10], Loss: 2.3175\n",
      "Epoch [3/10], Valid Accuracy: 9.5800, Valid Loss: 2.3124\n",
      "Epoch [4/10], Loss: 2.3132\n",
      "Epoch [4/10], Valid Accuracy: 11.3500, Valid Loss: 2.3272\n",
      "Epoch [5/10], Loss: 2.3136\n",
      "Epoch [5/10], Valid Accuracy: 11.3600, Valid Loss: 2.3110\n",
      "Epoch [6/10], Loss: 2.3137\n",
      "Epoch [6/10], Valid Accuracy: 9.7600, Valid Loss: 2.3175\n",
      "Epoch [7/10], Loss: 2.3137\n",
      "Epoch [7/10], Valid Accuracy: 11.3600, Valid Loss: 2.3191\n",
      "Epoch [8/10], Loss: 2.3132\n",
      "Epoch [8/10], Valid Accuracy: 9.5800, Valid Loss: 2.3193\n",
      "Epoch [9/10], Loss: 2.3140\n",
      "Epoch [9/10], Valid Accuracy: 11.3600, Valid Loss: 2.3183\n",
      "Epoch [10/10], Loss: 2.3137\n",
      "Epoch [10/10], Valid Accuracy: 11.3600, Valid Loss: 2.3129\n",
      "Epoch [1/10], Loss: 0.3385\n",
      "Epoch [1/10], Valid Accuracy: 92.7300, Valid Loss: 0.2705\n",
      "Epoch [2/10], Loss: 0.2591\n",
      "Epoch [2/10], Valid Accuracy: 93.1100, Valid Loss: 0.2673\n",
      "Epoch [3/10], Loss: 0.2443\n",
      "Epoch [3/10], Valid Accuracy: 93.0000, Valid Loss: 0.2892\n",
      "Epoch [4/10], Loss: 0.2399\n",
      "Epoch [4/10], Valid Accuracy: 94.1500, Valid Loss: 0.2726\n",
      "Epoch [5/10], Loss: 0.2288\n",
      "Epoch [5/10], Valid Accuracy: 93.2500, Valid Loss: 0.3156\n",
      "Epoch [6/10], Loss: 0.2272\n",
      "Epoch [6/10], Valid Accuracy: 94.9300, Valid Loss: 0.2910\n",
      "Epoch [7/10], Loss: 0.2222\n",
      "Epoch [7/10], Valid Accuracy: 93.6400, Valid Loss: 0.3089\n",
      "Epoch [8/10], Loss: 0.2190\n",
      "Epoch [8/10], Valid Accuracy: 93.8900, Valid Loss: 0.3180\n",
      "Epoch [9/10], Loss: 0.2123\n",
      "Epoch [9/10], Valid Accuracy: 94.2100, Valid Loss: 0.2997\n",
      "Epoch [10/10], Loss: 0.2140\n",
      "Epoch [10/10], Valid Accuracy: 93.8400, Valid Loss: 0.3456\n",
      "Epoch [1/10], Loss: 0.2007\n",
      "Epoch [1/10], Valid Accuracy: 96.8800, Valid Loss: 0.1049\n",
      "Epoch [2/10], Loss: 0.0876\n",
      "Epoch [2/10], Valid Accuracy: 97.3200, Valid Loss: 0.0894\n",
      "Epoch [3/10], Loss: 0.0608\n",
      "Epoch [3/10], Valid Accuracy: 97.4300, Valid Loss: 0.0893\n",
      "Epoch [4/10], Loss: 0.0452\n",
      "Epoch [4/10], Valid Accuracy: 97.3000, Valid Loss: 0.0953\n",
      "Epoch [5/10], Loss: 0.0393\n",
      "Epoch [5/10], Valid Accuracy: 97.5100, Valid Loss: 0.0879\n",
      "Epoch [6/10], Loss: 0.0299\n",
      "Epoch [6/10], Valid Accuracy: 97.4900, Valid Loss: 0.1001\n",
      "Epoch [7/10], Loss: 0.0284\n",
      "Epoch [7/10], Valid Accuracy: 97.7900, Valid Loss: 0.0990\n",
      "Epoch [8/10], Loss: 0.0267\n",
      "Epoch [8/10], Valid Accuracy: 97.3600, Valid Loss: 0.1137\n",
      "Epoch [9/10], Loss: 0.0239\n",
      "Epoch [9/10], Valid Accuracy: 97.5000, Valid Loss: 0.1151\n",
      "Epoch [10/10], Loss: 0.0221\n",
      "Epoch [10/10], Valid Accuracy: 97.6100, Valid Loss: 0.1171\n",
      "Epoch [1/10], Loss: 0.4065\n",
      "Epoch [1/10], Valid Accuracy: 93.6100, Valid Loss: 0.2271\n",
      "Epoch [2/10], Loss: 0.1968\n",
      "Epoch [2/10], Valid Accuracy: 95.1700, Valid Loss: 0.1632\n",
      "Epoch [3/10], Loss: 0.1429\n",
      "Epoch [3/10], Valid Accuracy: 96.1300, Valid Loss: 0.1284\n",
      "Epoch [4/10], Loss: 0.1109\n",
      "Epoch [4/10], Valid Accuracy: 97.0200, Valid Loss: 0.1028\n",
      "Epoch [5/10], Loss: 0.0894\n",
      "Epoch [5/10], Valid Accuracy: 97.2600, Valid Loss: 0.0911\n",
      "Epoch [6/10], Loss: 0.0746\n",
      "Epoch [6/10], Valid Accuracy: 97.4600, Valid Loss: 0.0838\n",
      "Epoch [7/10], Loss: 0.0628\n",
      "Epoch [7/10], Valid Accuracy: 97.8600, Valid Loss: 0.0741\n",
      "Epoch [8/10], Loss: 0.0534\n",
      "Epoch [8/10], Valid Accuracy: 97.8100, Valid Loss: 0.0733\n",
      "Epoch [9/10], Loss: 0.0458\n",
      "Epoch [9/10], Valid Accuracy: 97.8800, Valid Loss: 0.0689\n",
      "Epoch [10/10], Loss: 0.0392\n",
      "Epoch [10/10], Valid Accuracy: 98.0700, Valid Loss: 0.0642\n",
      "Epoch [1/10], Loss: 1.1271\n",
      "Epoch [1/10], Valid Accuracy: 87.0600, Valid Loss: 0.5734\n",
      "Epoch [2/10], Loss: 0.4841\n",
      "Epoch [2/10], Valid Accuracy: 89.8800, Valid Loss: 0.3944\n",
      "Epoch [3/10], Loss: 0.3778\n",
      "Epoch [3/10], Valid Accuracy: 90.8500, Valid Loss: 0.3354\n",
      "Epoch [4/10], Loss: 0.3315\n",
      "Epoch [4/10], Valid Accuracy: 91.5300, Valid Loss: 0.3030\n",
      "Epoch [5/10], Loss: 0.3034\n",
      "Epoch [5/10], Valid Accuracy: 92.0700, Valid Loss: 0.2822\n",
      "Epoch [6/10], Loss: 0.2827\n",
      "Epoch [6/10], Valid Accuracy: 92.4500, Valid Loss: 0.2655\n",
      "Epoch [7/10], Loss: 0.2662\n",
      "Epoch [7/10], Valid Accuracy: 92.8300, Valid Loss: 0.2526\n",
      "Epoch [8/10], Loss: 0.2518\n",
      "Epoch [8/10], Valid Accuracy: 93.1500, Valid Loss: 0.2409\n",
      "Epoch [9/10], Loss: 0.2394\n",
      "Epoch [9/10], Valid Accuracy: 93.5200, Valid Loss: 0.2303\n",
      "Epoch [10/10], Loss: 0.2284\n",
      "Epoch [10/10], Valid Accuracy: 93.6700, Valid Loss: 0.2210\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fdae3f1251c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdf_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "learning_rates = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "scores = []\n",
    "for lr in learning_rates:\n",
    "    net = get_model()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, \n",
    "                                                num_epochs=10, model=net, \n",
    "                                                optimizer=optimizer)\n",
    "    scores.append(val_acc)\n",
    "    \n",
    "\n",
    "df_1 = pd.DataFrame({'lr': learning_rates, 'accuracy': scores})\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) The best hidden layer size is    \n",
    "## Some of the models are overfitting past epoch 5 which can be seen as the validation accuracy goes down in further epochs and the validation loss goes up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decay</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>97.69</td>\n",
       "      <td>0.195473</td>\n",
       "      <td>0.015452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>97.73</td>\n",
       "      <td>0.109670</td>\n",
       "      <td>0.028258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>97.29</td>\n",
       "      <td>0.086315</td>\n",
       "      <td>0.066569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>95.72</td>\n",
       "      <td>0.156220</td>\n",
       "      <td>0.166869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>89.31</td>\n",
       "      <td>0.440048</td>\n",
       "      <td>0.467849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>84.42</td>\n",
       "      <td>0.800058</td>\n",
       "      <td>0.815454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    decay  val_acc  val_loss  train_loss\n",
       "0  0.0000    97.69  0.195473    0.015452\n",
       "1  0.0001    97.73  0.109670    0.028258\n",
       "2  0.0010    97.29  0.086315    0.066569\n",
       "3  0.0100    95.72  0.156220    0.166869\n",
       "4  0.1000    89.31  0.440048    0.467849\n",
       "5  0.3000    84.42  0.800058    0.815454"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.9859\n",
      "Epoch [1/10], Valid Accuracy: 77.2100, Valid Loss: 0.7435\n",
      "Epoch [2/10], Loss: 0.7655\n",
      "Epoch [2/10], Valid Accuracy: 78.4900, Valid Loss: 0.7108\n",
      "Epoch [3/10], Loss: 0.7201\n",
      "Epoch [3/10], Valid Accuracy: 78.9300, Valid Loss: 0.6881\n",
      "Epoch [4/10], Loss: 0.7031\n",
      "Epoch [4/10], Valid Accuracy: 77.7600, Valid Loss: 0.7476\n",
      "Epoch [5/10], Loss: 0.7004\n",
      "Epoch [5/10], Valid Accuracy: 77.9900, Valid Loss: 0.7170\n",
      "Epoch [6/10], Loss: 0.6981\n",
      "Epoch [6/10], Valid Accuracy: 80.2000, Valid Loss: 0.6734\n",
      "Epoch [7/10], Loss: 0.6973\n",
      "Epoch [7/10], Valid Accuracy: 79.0800, Valid Loss: 0.7086\n",
      "Epoch [8/10], Loss: 0.6943\n",
      "Epoch [8/10], Valid Accuracy: 79.9000, Valid Loss: 0.6844\n",
      "Epoch [9/10], Loss: 0.6870\n",
      "Epoch [9/10], Valid Accuracy: 78.2200, Valid Loss: 0.7130\n",
      "Epoch [10/10], Loss: 0.6916\n",
      "Epoch [10/10], Valid Accuracy: 80.5900, Valid Loss: 0.6675\n",
      "Epoch [1/10], Loss: 0.3318\n",
      "Epoch [1/10], Valid Accuracy: 91.6800, Valid Loss: 0.2774\n",
      "Epoch [2/10], Loss: 0.2666\n",
      "Epoch [2/10], Valid Accuracy: 92.2800, Valid Loss: 0.2939\n",
      "Epoch [3/10], Loss: 0.2522\n",
      "Epoch [3/10], Valid Accuracy: 93.2000, Valid Loss: 0.2660\n",
      "Epoch [4/10], Loss: 0.2412\n",
      "Epoch [4/10], Valid Accuracy: 93.9400, Valid Loss: 0.2478\n",
      "Epoch [5/10], Loss: 0.2361\n",
      "Epoch [5/10], Valid Accuracy: 93.4300, Valid Loss: 0.2706\n",
      "Epoch [6/10], Loss: 0.2337\n",
      "Epoch [6/10], Valid Accuracy: 92.9400, Valid Loss: 0.3175\n",
      "Epoch [7/10], Loss: 0.2326\n",
      "Epoch [7/10], Valid Accuracy: 93.4200, Valid Loss: 0.2779\n",
      "Epoch [8/10], Loss: 0.2278\n",
      "Epoch [8/10], Valid Accuracy: 93.7100, Valid Loss: 0.2783\n",
      "Epoch [9/10], Loss: 0.2235\n",
      "Epoch [9/10], Valid Accuracy: 93.5600, Valid Loss: 0.2944\n",
      "Epoch [10/10], Loss: 0.2328\n",
      "Epoch [10/10], Valid Accuracy: 92.9800, Valid Loss: 0.3632\n",
      "Epoch [1/10], Loss: 0.3336\n",
      "Epoch [1/10], Valid Accuracy: 93.8800, Valid Loss: 0.2257\n",
      "Epoch [2/10], Loss: 0.2563\n",
      "Epoch [2/10], Valid Accuracy: 93.2000, Valid Loss: 0.3034\n",
      "Epoch [3/10], Loss: 0.2487\n",
      "Epoch [3/10], Valid Accuracy: 93.7000, Valid Loss: 0.2589\n",
      "Epoch [4/10], Loss: 0.2367\n",
      "Epoch [4/10], Valid Accuracy: 94.1800, Valid Loss: 0.2355\n",
      "Epoch [5/10], Loss: 0.2312\n",
      "Epoch [5/10], Valid Accuracy: 93.7200, Valid Loss: 0.2743\n",
      "Epoch [6/10], Loss: 0.2248\n",
      "Epoch [6/10], Valid Accuracy: 94.1300, Valid Loss: 0.2774\n",
      "Epoch [7/10], Loss: 0.2325\n",
      "Epoch [7/10], Valid Accuracy: 94.3500, Valid Loss: 0.2884\n",
      "Epoch [8/10], Loss: 0.2185\n",
      "Epoch [8/10], Valid Accuracy: 94.0600, Valid Loss: 0.2649\n",
      "Epoch [9/10], Loss: 0.2303\n",
      "Epoch [9/10], Valid Accuracy: 93.3100, Valid Loss: 0.3481\n",
      "Epoch [10/10], Loss: 0.2180\n",
      "Epoch [10/10], Valid Accuracy: 94.0800, Valid Loss: 0.3045\n",
      "Epoch [1/10], Loss: 0.3340\n",
      "Epoch [1/10], Valid Accuracy: 93.1500, Valid Loss: 0.2612\n",
      "Epoch [2/10], Loss: 0.2562\n",
      "Epoch [2/10], Valid Accuracy: 93.6500, Valid Loss: 0.2522\n",
      "Epoch [3/10], Loss: 0.2466\n",
      "Epoch [3/10], Valid Accuracy: 93.6700, Valid Loss: 0.2594\n",
      "Epoch [4/10], Loss: 0.2312\n",
      "Epoch [4/10], Valid Accuracy: 94.0500, Valid Loss: 0.2553\n",
      "Epoch [5/10], Loss: 0.2340\n",
      "Epoch [5/10], Valid Accuracy: 93.9500, Valid Loss: 0.3395\n",
      "Epoch [6/10], Loss: 0.2298\n",
      "Epoch [6/10], Valid Accuracy: 94.4600, Valid Loss: 0.2839\n",
      "Epoch [7/10], Loss: 0.2336\n",
      "Epoch [7/10], Valid Accuracy: 94.5000, Valid Loss: 0.2841\n",
      "Epoch [8/10], Loss: 0.2204\n",
      "Epoch [8/10], Valid Accuracy: 94.7100, Valid Loss: 0.2760\n",
      "Epoch [9/10], Loss: 0.2136\n",
      "Epoch [9/10], Valid Accuracy: 94.1900, Valid Loss: 0.3387\n",
      "Epoch [10/10], Loss: 0.2260\n",
      "Epoch [10/10], Valid Accuracy: 94.1800, Valid Loss: 0.3273\n",
      "Epoch [1/10], Loss: 0.3678\n",
      "Epoch [1/10], Valid Accuracy: 93.5500, Valid Loss: 0.2384\n",
      "Epoch [2/10], Loss: 0.2764\n",
      "Epoch [2/10], Valid Accuracy: 93.4900, Valid Loss: 0.2547\n",
      "Epoch [3/10], Loss: 0.2612\n",
      "Epoch [3/10], Valid Accuracy: 94.2600, Valid Loss: 0.2549\n",
      "Epoch [4/10], Loss: 0.2500\n",
      "Epoch [4/10], Valid Accuracy: 93.6100, Valid Loss: 0.2907\n",
      "Epoch [5/10], Loss: 0.2387\n",
      "Epoch [5/10], Valid Accuracy: 94.3800, Valid Loss: 0.2932\n",
      "Epoch [6/10], Loss: 0.2251\n",
      "Epoch [6/10], Valid Accuracy: 94.2500, Valid Loss: 0.2855\n",
      "Epoch [7/10], Loss: 0.2252\n",
      "Epoch [7/10], Valid Accuracy: 93.4000, Valid Loss: 0.3820\n",
      "Epoch [8/10], Loss: 0.2176\n",
      "Epoch [8/10], Valid Accuracy: 94.5600, Valid Loss: 0.2698\n",
      "Epoch [9/10], Loss: 0.2132\n",
      "Epoch [9/10], Valid Accuracy: 94.5700, Valid Loss: 0.3081\n",
      "Epoch [10/10], Loss: 0.2122\n",
      "Epoch [10/10], Valid Accuracy: 94.5800, Valid Loss: 0.3354\n",
      "Epoch [1/10], Loss: 0.3906\n",
      "Epoch [1/10], Valid Accuracy: 93.2900, Valid Loss: 0.2767\n",
      "Epoch [2/10], Loss: 0.2779\n",
      "Epoch [2/10], Valid Accuracy: 91.9300, Valid Loss: 0.3613\n",
      "Epoch [3/10], Loss: 0.2518\n",
      "Epoch [3/10], Valid Accuracy: 93.6500, Valid Loss: 0.3014\n",
      "Epoch [4/10], Loss: 0.2347\n",
      "Epoch [4/10], Valid Accuracy: 94.2800, Valid Loss: 0.2658\n",
      "Epoch [5/10], Loss: 0.2340\n",
      "Epoch [5/10], Valid Accuracy: 93.5100, Valid Loss: 0.3024\n",
      "Epoch [6/10], Loss: 0.2243\n",
      "Epoch [6/10], Valid Accuracy: 94.1300, Valid Loss: 0.3059\n",
      "Epoch [7/10], Loss: 0.2233\n",
      "Epoch [7/10], Valid Accuracy: 93.5400, Valid Loss: 0.2862\n",
      "Epoch [8/10], Loss: 0.2331\n",
      "Epoch [8/10], Valid Accuracy: 93.2300, Valid Loss: 0.3720\n",
      "Epoch [9/10], Loss: 0.2167\n",
      "Epoch [9/10], Valid Accuracy: 95.0400, Valid Loss: 0.2737\n",
      "Epoch [10/10], Loss: 0.2241\n",
      "Epoch [10/10], Valid Accuracy: 94.0100, Valid Loss: 0.3106\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ea0a1be63c0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdf_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         ]\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "neurons = [10, 50, 100, 300, 1000, 2000]\n",
    "rows = []\n",
    "for neuron in neurons:\n",
    "    data = {}\n",
    "    net = get_model(M=neuron)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, \n",
    "                                            num_epochs=10, model=net, \n",
    "                                            optimizer=optimizer)\n",
    "    data['neuron'] = neuron\n",
    "    data['val_acc'] = val_acc\n",
    "    data['val_loss'] = val_loss\n",
    "    data['train_loss'] = train_loss\n",
    "    rows.append(data)\n",
    "        \n",
    "        \n",
    "df_2 = pd.DataFrame(rows)    \n",
    "df_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neuron</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>80.59</td>\n",
       "      <td>0.667514</td>\n",
       "      <td>0.691556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>92.98</td>\n",
       "      <td>0.363225</td>\n",
       "      <td>0.232805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>94.08</td>\n",
       "      <td>0.304494</td>\n",
       "      <td>0.217970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>94.18</td>\n",
       "      <td>0.327253</td>\n",
       "      <td>0.226029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>94.58</td>\n",
       "      <td>0.335383</td>\n",
       "      <td>0.212230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>94.01</td>\n",
       "      <td>0.310637</td>\n",
       "      <td>0.224147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neuron  val_acc  val_loss  train_loss\n",
       "0      10    80.59  0.667514    0.691556\n",
       "1      50    92.98  0.363225    0.232805\n",
       "2     100    94.08  0.304494    0.217970\n",
       "3     300    94.18  0.327253    0.226029\n",
       "4    1000    94.58  0.335383    0.212230\n",
       "5    2000    94.01  0.310637    0.224147"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.DataFrame(rows)    \n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3) Weight Decay\n",
    "## The best validation accuracy was with weight decay of 0.0001. The validation accuracy is better with the highest being 97.73\n",
    "To add L2 regularization use the `weight_decay` argument on the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decay</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>97.69</td>\n",
       "      <td>0.195473</td>\n",
       "      <td>0.015452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>97.73</td>\n",
       "      <td>0.109670</td>\n",
       "      <td>0.028258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>97.29</td>\n",
       "      <td>0.086315</td>\n",
       "      <td>0.066569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>95.72</td>\n",
       "      <td>0.156220</td>\n",
       "      <td>0.166869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>89.31</td>\n",
       "      <td>0.440048</td>\n",
       "      <td>0.467849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>84.42</td>\n",
       "      <td>0.800058</td>\n",
       "      <td>0.815454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    decay  val_acc  val_loss  train_loss\n",
       "0  0.0000    97.69  0.195473    0.015452\n",
       "1  0.0001    97.73  0.109670    0.028258\n",
       "2  0.0010    97.29  0.086315    0.066569\n",
       "3  0.0100    95.72  0.156220    0.166869\n",
       "4  0.1000    89.31  0.440048    0.467849\n",
       "5  0.3000    84.42  0.800058    0.815454"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.1840\n",
      "Epoch [1/20], Valid Accuracy: 96.8300, Valid Loss: 0.1014\n",
      "Epoch [2/20], Loss: 0.0888\n",
      "Epoch [2/20], Valid Accuracy: 97.4000, Valid Loss: 0.0832\n",
      "Epoch [3/20], Loss: 0.0638\n",
      "Epoch [3/20], Valid Accuracy: 97.9000, Valid Loss: 0.0830\n",
      "Epoch [4/20], Loss: 0.0484\n",
      "Epoch [4/20], Valid Accuracy: 97.7500, Valid Loss: 0.0890\n",
      "Epoch [5/20], Loss: 0.0422\n",
      "Epoch [5/20], Valid Accuracy: 97.8900, Valid Loss: 0.0933\n",
      "Epoch [6/20], Loss: 0.0371\n",
      "Epoch [6/20], Valid Accuracy: 97.6300, Valid Loss: 0.1087\n",
      "Epoch [7/20], Loss: 0.0298\n",
      "Epoch [7/20], Valid Accuracy: 98.0600, Valid Loss: 0.0923\n",
      "Epoch [8/20], Loss: 0.0313\n",
      "Epoch [8/20], Valid Accuracy: 97.9600, Valid Loss: 0.1135\n",
      "Epoch [9/20], Loss: 0.0278\n",
      "Epoch [9/20], Valid Accuracy: 97.9300, Valid Loss: 0.1071\n",
      "Epoch [10/20], Loss: 0.0254\n",
      "Epoch [10/20], Valid Accuracy: 97.8500, Valid Loss: 0.1347\n",
      "Epoch [11/20], Loss: 0.0253\n",
      "Epoch [11/20], Valid Accuracy: 97.5700, Valid Loss: 0.1575\n",
      "Epoch [12/20], Loss: 0.0241\n",
      "Epoch [12/20], Valid Accuracy: 97.9700, Valid Loss: 0.1408\n",
      "Epoch [13/20], Loss: 0.0207\n",
      "Epoch [13/20], Valid Accuracy: 97.7600, Valid Loss: 0.1444\n",
      "Epoch [14/20], Loss: 0.0217\n",
      "Epoch [14/20], Valid Accuracy: 98.2400, Valid Loss: 0.1247\n",
      "Epoch [15/20], Loss: 0.0231\n",
      "Epoch [15/20], Valid Accuracy: 97.9400, Valid Loss: 0.1522\n",
      "Epoch [16/20], Loss: 0.0200\n",
      "Epoch [16/20], Valid Accuracy: 98.0900, Valid Loss: 0.1431\n",
      "Epoch [17/20], Loss: 0.0187\n",
      "Epoch [17/20], Valid Accuracy: 97.8000, Valid Loss: 0.1927\n",
      "Epoch [18/20], Loss: 0.0214\n",
      "Epoch [18/20], Valid Accuracy: 98.0300, Valid Loss: 0.1677\n",
      "Epoch [19/20], Loss: 0.0176\n",
      "Epoch [19/20], Valid Accuracy: 97.5800, Valid Loss: 0.1898\n",
      "Epoch [20/20], Loss: 0.0155\n",
      "Epoch [20/20], Valid Accuracy: 97.6900, Valid Loss: 0.1955\n",
      "Epoch [1/20], Loss: 0.1916\n",
      "Epoch [1/20], Valid Accuracy: 96.9100, Valid Loss: 0.1032\n",
      "Epoch [2/20], Loss: 0.0957\n",
      "Epoch [2/20], Valid Accuracy: 97.0600, Valid Loss: 0.0951\n",
      "Epoch [3/20], Loss: 0.0771\n",
      "Epoch [3/20], Valid Accuracy: 97.1600, Valid Loss: 0.0938\n",
      "Epoch [4/20], Loss: 0.0589\n",
      "Epoch [4/20], Valid Accuracy: 97.2100, Valid Loss: 0.0929\n",
      "Epoch [5/20], Loss: 0.0558\n",
      "Epoch [5/20], Valid Accuracy: 97.4200, Valid Loss: 0.0869\n",
      "Epoch [6/20], Loss: 0.0503\n",
      "Epoch [6/20], Valid Accuracy: 97.3600, Valid Loss: 0.0979\n",
      "Epoch [7/20], Loss: 0.0448\n",
      "Epoch [7/20], Valid Accuracy: 97.6500, Valid Loss: 0.0871\n",
      "Epoch [8/20], Loss: 0.0428\n",
      "Epoch [8/20], Valid Accuracy: 97.4500, Valid Loss: 0.1063\n",
      "Epoch [9/20], Loss: 0.0425\n",
      "Epoch [9/20], Valid Accuracy: 97.2400, Valid Loss: 0.1118\n",
      "Epoch [10/20], Loss: 0.0384\n",
      "Epoch [10/20], Valid Accuracy: 97.5500, Valid Loss: 0.1000\n",
      "Epoch [11/20], Loss: 0.0368\n",
      "Epoch [11/20], Valid Accuracy: 97.9800, Valid Loss: 0.0875\n",
      "Epoch [12/20], Loss: 0.0357\n",
      "Epoch [12/20], Valid Accuracy: 97.9800, Valid Loss: 0.0849\n",
      "Epoch [13/20], Loss: 0.0318\n",
      "Epoch [13/20], Valid Accuracy: 97.7000, Valid Loss: 0.1123\n",
      "Epoch [14/20], Loss: 0.0354\n",
      "Epoch [14/20], Valid Accuracy: 97.5700, Valid Loss: 0.0990\n",
      "Epoch [15/20], Loss: 0.0336\n",
      "Epoch [15/20], Valid Accuracy: 97.8800, Valid Loss: 0.0835\n",
      "Epoch [16/20], Loss: 0.0300\n",
      "Epoch [16/20], Valid Accuracy: 97.7200, Valid Loss: 0.1076\n",
      "Epoch [17/20], Loss: 0.0313\n",
      "Epoch [17/20], Valid Accuracy: 97.1000, Valid Loss: 0.1353\n",
      "Epoch [18/20], Loss: 0.0306\n",
      "Epoch [18/20], Valid Accuracy: 97.5900, Valid Loss: 0.1054\n",
      "Epoch [19/20], Loss: 0.0327\n",
      "Epoch [19/20], Valid Accuracy: 97.9000, Valid Loss: 0.1049\n",
      "Epoch [20/20], Loss: 0.0283\n",
      "Epoch [20/20], Valid Accuracy: 97.7300, Valid Loss: 0.1097\n",
      "Epoch [1/20], Loss: 0.2053\n",
      "Epoch [1/20], Valid Accuracy: 96.0100, Valid Loss: 0.1257\n",
      "Epoch [2/20], Loss: 0.1216\n",
      "Epoch [2/20], Valid Accuracy: 96.7000, Valid Loss: 0.1076\n",
      "Epoch [3/20], Loss: 0.1005\n",
      "Epoch [3/20], Valid Accuracy: 96.3800, Valid Loss: 0.1258\n",
      "Epoch [4/20], Loss: 0.0925\n",
      "Epoch [4/20], Valid Accuracy: 97.5800, Valid Loss: 0.0774\n",
      "Epoch [5/20], Loss: 0.0839\n",
      "Epoch [5/20], Valid Accuracy: 97.5100, Valid Loss: 0.0853\n",
      "Epoch [6/20], Loss: 0.0808\n",
      "Epoch [6/20], Valid Accuracy: 97.2800, Valid Loss: 0.0901\n",
      "Epoch [7/20], Loss: 0.0789\n",
      "Epoch [7/20], Valid Accuracy: 95.9300, Valid Loss: 0.1285\n",
      "Epoch [8/20], Loss: 0.0747\n",
      "Epoch [8/20], Valid Accuracy: 96.9900, Valid Loss: 0.0939\n",
      "Epoch [9/20], Loss: 0.0747\n",
      "Epoch [9/20], Valid Accuracy: 97.1700, Valid Loss: 0.0950\n",
      "Epoch [10/20], Loss: 0.0733\n",
      "Epoch [10/20], Valid Accuracy: 97.4300, Valid Loss: 0.0841\n",
      "Epoch [11/20], Loss: 0.0697\n",
      "Epoch [11/20], Valid Accuracy: 97.0800, Valid Loss: 0.0949\n",
      "Epoch [12/20], Loss: 0.0719\n",
      "Epoch [12/20], Valid Accuracy: 97.5000, Valid Loss: 0.0816\n",
      "Epoch [13/20], Loss: 0.0689\n",
      "Epoch [13/20], Valid Accuracy: 97.3900, Valid Loss: 0.0867\n",
      "Epoch [14/20], Loss: 0.0681\n",
      "Epoch [14/20], Valid Accuracy: 96.6600, Valid Loss: 0.1056\n",
      "Epoch [15/20], Loss: 0.0690\n",
      "Epoch [15/20], Valid Accuracy: 97.2700, Valid Loss: 0.0834\n",
      "Epoch [16/20], Loss: 0.0666\n",
      "Epoch [16/20], Valid Accuracy: 97.3200, Valid Loss: 0.0864\n",
      "Epoch [17/20], Loss: 0.0661\n",
      "Epoch [17/20], Valid Accuracy: 97.5300, Valid Loss: 0.0779\n",
      "Epoch [18/20], Loss: 0.0667\n",
      "Epoch [18/20], Valid Accuracy: 97.3800, Valid Loss: 0.0834\n",
      "Epoch [19/20], Loss: 0.0641\n",
      "Epoch [19/20], Valid Accuracy: 97.4700, Valid Loss: 0.0809\n",
      "Epoch [20/20], Loss: 0.0666\n",
      "Epoch [20/20], Valid Accuracy: 97.2900, Valid Loss: 0.0863\n",
      "Epoch [1/20], Loss: 0.2911\n",
      "Epoch [1/20], Valid Accuracy: 93.1700, Valid Loss: 0.2277\n",
      "Epoch [2/20], Loss: 0.2085\n",
      "Epoch [2/20], Valid Accuracy: 94.8600, Valid Loss: 0.1795\n",
      "Epoch [3/20], Loss: 0.1896\n",
      "Epoch [3/20], Valid Accuracy: 95.1100, Valid Loss: 0.1701\n",
      "Epoch [4/20], Loss: 0.1796\n",
      "Epoch [4/20], Valid Accuracy: 95.9900, Valid Loss: 0.1549\n",
      "Epoch [5/20], Loss: 0.1762\n",
      "Epoch [5/20], Valid Accuracy: 95.3100, Valid Loss: 0.1603\n",
      "Epoch [6/20], Loss: 0.1738\n",
      "Epoch [6/20], Valid Accuracy: 95.1900, Valid Loss: 0.1707\n",
      "Epoch [7/20], Loss: 0.1707\n",
      "Epoch [7/20], Valid Accuracy: 94.7900, Valid Loss: 0.1810\n",
      "Epoch [8/20], Loss: 0.1704\n",
      "Epoch [8/20], Valid Accuracy: 95.2400, Valid Loss: 0.1641\n",
      "Epoch [9/20], Loss: 0.1691\n",
      "Epoch [9/20], Valid Accuracy: 95.4700, Valid Loss: 0.1560\n",
      "Epoch [10/20], Loss: 0.1687\n",
      "Epoch [10/20], Valid Accuracy: 95.9600, Valid Loss: 0.1448\n",
      "Epoch [11/20], Loss: 0.1680\n",
      "Epoch [11/20], Valid Accuracy: 95.6800, Valid Loss: 0.1544\n",
      "Epoch [12/20], Loss: 0.1676\n",
      "Epoch [12/20], Valid Accuracy: 95.5400, Valid Loss: 0.1627\n",
      "Epoch [13/20], Loss: 0.1658\n",
      "Epoch [13/20], Valid Accuracy: 95.9700, Valid Loss: 0.1487\n",
      "Epoch [14/20], Loss: 0.1667\n",
      "Epoch [14/20], Valid Accuracy: 96.0800, Valid Loss: 0.1464\n",
      "Epoch [15/20], Loss: 0.1679\n",
      "Epoch [15/20], Valid Accuracy: 95.4800, Valid Loss: 0.1614\n",
      "Epoch [16/20], Loss: 0.1651\n",
      "Epoch [16/20], Valid Accuracy: 95.3900, Valid Loss: 0.1600\n",
      "Epoch [17/20], Loss: 0.1674\n",
      "Epoch [17/20], Valid Accuracy: 95.7600, Valid Loss: 0.1545\n",
      "Epoch [18/20], Loss: 0.1663\n",
      "Epoch [18/20], Valid Accuracy: 95.3000, Valid Loss: 0.1647\n",
      "Epoch [19/20], Loss: 0.1661\n",
      "Epoch [19/20], Valid Accuracy: 94.4600, Valid Loss: 0.1860\n",
      "Epoch [20/20], Loss: 0.1669\n",
      "Epoch [20/20], Valid Accuracy: 95.7200, Valid Loss: 0.1562\n",
      "Epoch [1/20], Loss: 0.5646\n",
      "Epoch [1/20], Valid Accuracy: 84.9700, Valid Loss: 0.5365\n",
      "Epoch [2/20], Loss: 0.4970\n",
      "Epoch [2/20], Valid Accuracy: 88.6300, Valid Loss: 0.4692\n",
      "Epoch [3/20], Loss: 0.4820\n",
      "Epoch [3/20], Valid Accuracy: 89.7100, Valid Loss: 0.4454\n",
      "Epoch [4/20], Loss: 0.4760\n",
      "Epoch [4/20], Valid Accuracy: 89.3600, Valid Loss: 0.4484\n",
      "Epoch [5/20], Loss: 0.4725\n",
      "Epoch [5/20], Valid Accuracy: 89.9500, Valid Loss: 0.4351\n",
      "Epoch [6/20], Loss: 0.4706\n",
      "Epoch [6/20], Valid Accuracy: 89.2900, Valid Loss: 0.4524\n",
      "Epoch [7/20], Loss: 0.4693\n",
      "Epoch [7/20], Valid Accuracy: 89.1900, Valid Loss: 0.4534\n",
      "Epoch [8/20], Loss: 0.4683\n",
      "Epoch [8/20], Valid Accuracy: 90.1200, Valid Loss: 0.4405\n",
      "Epoch [9/20], Loss: 0.4680\n",
      "Epoch [9/20], Valid Accuracy: 90.0300, Valid Loss: 0.4346\n",
      "Epoch [10/20], Loss: 0.4674\n",
      "Epoch [10/20], Valid Accuracy: 89.6000, Valid Loss: 0.4445\n",
      "Epoch [11/20], Loss: 0.4677\n",
      "Epoch [11/20], Valid Accuracy: 89.4900, Valid Loss: 0.4397\n",
      "Epoch [12/20], Loss: 0.4682\n",
      "Epoch [12/20], Valid Accuracy: 89.3300, Valid Loss: 0.4410\n",
      "Epoch [13/20], Loss: 0.4681\n",
      "Epoch [13/20], Valid Accuracy: 89.6000, Valid Loss: 0.4536\n",
      "Epoch [14/20], Loss: 0.4687\n",
      "Epoch [14/20], Valid Accuracy: 89.7700, Valid Loss: 0.4377\n",
      "Epoch [15/20], Loss: 0.4676\n",
      "Epoch [15/20], Valid Accuracy: 89.5500, Valid Loss: 0.4499\n",
      "Epoch [16/20], Loss: 0.4674\n",
      "Epoch [16/20], Valid Accuracy: 89.1700, Valid Loss: 0.4576\n",
      "Epoch [17/20], Loss: 0.4675\n",
      "Epoch [17/20], Valid Accuracy: 89.5500, Valid Loss: 0.4420\n",
      "Epoch [18/20], Loss: 0.4672\n",
      "Epoch [18/20], Valid Accuracy: 90.3300, Valid Loss: 0.4332\n",
      "Epoch [19/20], Loss: 0.4675\n",
      "Epoch [19/20], Valid Accuracy: 89.2100, Valid Loss: 0.4478\n",
      "Epoch [20/20], Loss: 0.4678\n",
      "Epoch [20/20], Valid Accuracy: 89.3100, Valid Loss: 0.4400\n",
      "Epoch [1/20], Loss: 0.8964\n",
      "Epoch [1/20], Valid Accuracy: 84.4100, Valid Loss: 0.8406\n",
      "Epoch [2/20], Loss: 0.8442\n",
      "Epoch [2/20], Valid Accuracy: 83.5100, Valid Loss: 0.7968\n",
      "Epoch [3/20], Loss: 0.8288\n",
      "Epoch [3/20], Valid Accuracy: 80.1400, Valid Loss: 0.8011\n",
      "Epoch [4/20], Loss: 0.8242\n",
      "Epoch [4/20], Valid Accuracy: 82.1700, Valid Loss: 0.8072\n",
      "Epoch [5/20], Loss: 0.8218\n",
      "Epoch [5/20], Valid Accuracy: 85.3100, Valid Loss: 0.7937\n",
      "Epoch [6/20], Loss: 0.8186\n",
      "Epoch [6/20], Valid Accuracy: 84.5700, Valid Loss: 0.7886\n",
      "Epoch [7/20], Loss: 0.8172\n",
      "Epoch [7/20], Valid Accuracy: 86.3000, Valid Loss: 0.8005\n",
      "Epoch [8/20], Loss: 0.8195\n",
      "Epoch [8/20], Valid Accuracy: 85.5300, Valid Loss: 0.7877\n",
      "Epoch [9/20], Loss: 0.8165\n",
      "Epoch [9/20], Valid Accuracy: 83.9200, Valid Loss: 0.7919\n",
      "Epoch [10/20], Loss: 0.8158\n",
      "Epoch [10/20], Valid Accuracy: 83.1500, Valid Loss: 0.7946\n",
      "Epoch [11/20], Loss: 0.8156\n",
      "Epoch [11/20], Valid Accuracy: 85.4000, Valid Loss: 0.7897\n",
      "Epoch [12/20], Loss: 0.8149\n",
      "Epoch [12/20], Valid Accuracy: 84.5400, Valid Loss: 0.7957\n",
      "Epoch [13/20], Loss: 0.8155\n",
      "Epoch [13/20], Valid Accuracy: 84.9200, Valid Loss: 0.7872\n",
      "Epoch [14/20], Loss: 0.8148\n",
      "Epoch [14/20], Valid Accuracy: 84.4400, Valid Loss: 0.7972\n",
      "Epoch [15/20], Loss: 0.8156\n",
      "Epoch [15/20], Valid Accuracy: 85.0000, Valid Loss: 0.7929\n",
      "Epoch [16/20], Loss: 0.8142\n",
      "Epoch [16/20], Valid Accuracy: 86.2000, Valid Loss: 0.7947\n",
      "Epoch [17/20], Loss: 0.8143\n",
      "Epoch [17/20], Valid Accuracy: 82.9300, Valid Loss: 0.8047\n",
      "Epoch [18/20], Loss: 0.8145\n",
      "Epoch [18/20], Valid Accuracy: 85.6000, Valid Loss: 0.7874\n",
      "Epoch [19/20], Loss: 0.8141\n",
      "Epoch [19/20], Valid Accuracy: 85.2300, Valid Loss: 0.7920\n",
      "Epoch [20/20], Loss: 0.8155\n",
      "Epoch [20/20], Valid Accuracy: 84.4200, Valid Loss: 0.8001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decay</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>97.69</td>\n",
       "      <td>0.195473</td>\n",
       "      <td>0.015452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>97.73</td>\n",
       "      <td>0.109670</td>\n",
       "      <td>0.028258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>97.29</td>\n",
       "      <td>0.086315</td>\n",
       "      <td>0.066569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>95.72</td>\n",
       "      <td>0.156220</td>\n",
       "      <td>0.166869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>89.31</td>\n",
       "      <td>0.440048</td>\n",
       "      <td>0.467849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>84.42</td>\n",
       "      <td>0.800058</td>\n",
       "      <td>0.815454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    decay  val_acc  val_loss  train_loss\n",
       "0  0.0000    97.69  0.195473    0.015452\n",
       "1  0.0001    97.73  0.109670    0.028258\n",
       "2  0.0010    97.29  0.086315    0.066569\n",
       "3  0.0100    95.72  0.156220    0.166869\n",
       "4  0.1000    89.31  0.440048    0.467849\n",
       "5  0.3000    84.42  0.800058    0.815454"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2 weight decay rates\n",
    "decays = [0, 0.0001, 0.001, 0.01, 0.1, 0.3]\n",
    "rows = []\n",
    "for decay in decays:\n",
    "    data = {}\n",
    "    net = get_model(M=neuron)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=decay)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, \n",
    "                                            num_epochs=20, model=net, \n",
    "                                            optimizer=optimizer)\n",
    "    data['decay'] = decay\n",
    "    data['val_acc'] = val_acc\n",
    "    data['val_loss'] = val_loss\n",
    "    data['train_loss'] = train_loss\n",
    "    rows.append(data)\n",
    "        \n",
    "        \n",
    "df_3 = pd.DataFrame(rows) \n",
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_v2(M = 300, p=0):\n",
    "    modules = []\n",
    "    modules.append(nn.Linear(28*28, M))\n",
    "    modules.append(nn.ReLU())\n",
    "    if p > 0:\n",
    "        modules.append(nn.Dropout(p))\n",
    "    modules.append(nn.Linear(M, 10))\n",
    "    return nn.Sequential(*modules) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = get_model_v2(M = 300, p=0.1)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4) Models with Dropout \n",
    "\n",
    "## The table below shows the train loss, validation loss, and validation accuracy for dropout rates of 0.1, 0.2, 0.3, 0.4\n",
    "## Dropout rate of 0.7 performed the best. Literature says that the dropout rate between 0. and 0.5 works the best \n",
    "\n",
    "\n",
    "## The choice of dropout parameter affects the model similar to how trees in a random forest only see a subset of the features to prevent overfitting\n",
    "\n",
    "## Compared to L2 regularization the validation accuracy scores are better; however, I only trained for 5 epochs due to the time constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>97.41</td>\n",
       "      <td>0.087582</td>\n",
       "      <td>0.039432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>97.38</td>\n",
       "      <td>0.093658</td>\n",
       "      <td>0.039167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>97.85</td>\n",
       "      <td>0.075085</td>\n",
       "      <td>0.040015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>97.81</td>\n",
       "      <td>0.082086</td>\n",
       "      <td>0.042351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>97.28</td>\n",
       "      <td>0.097819</td>\n",
       "      <td>0.040616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>97.74</td>\n",
       "      <td>0.080882</td>\n",
       "      <td>0.041318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>97.38</td>\n",
       "      <td>0.094288</td>\n",
       "      <td>0.046152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>97.87</td>\n",
       "      <td>0.080707</td>\n",
       "      <td>0.047316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>97.63</td>\n",
       "      <td>0.078330</td>\n",
       "      <td>0.053195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout  val_acc  val_loss  train_loss\n",
       "0      0.1    97.41  0.087582    0.039432\n",
       "1      0.2    97.38  0.093658    0.039167\n",
       "2      0.3    97.85  0.075085    0.040015\n",
       "3      0.4    97.81  0.082086    0.042351\n",
       "4      0.5    97.28  0.097819    0.040616\n",
       "5      0.6    97.74  0.080882    0.041318\n",
       "6      0.7    97.38  0.094288    0.046152\n",
       "7      0.8    97.87  0.080707    0.047316\n",
       "8      0.9    97.63  0.078330    0.053195"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        \n",
    "df_4 = pd.DataFrame(rows) \n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.2135\n",
      "Epoch [1/5], Valid Accuracy: 96.4800, Valid Loss: 0.1113\n",
      "Epoch [2/5], Loss: 0.0880\n",
      "Epoch [2/5], Valid Accuracy: 97.1500, Valid Loss: 0.0873\n",
      "Epoch [3/5], Loss: 0.0621\n",
      "Epoch [3/5], Valid Accuracy: 97.2700, Valid Loss: 0.0893\n",
      "Epoch [4/5], Loss: 0.0480\n",
      "Epoch [4/5], Valid Accuracy: 97.3800, Valid Loss: 0.0925\n",
      "Epoch [5/5], Loss: 0.0394\n",
      "Epoch [5/5], Valid Accuracy: 97.4100, Valid Loss: 0.0876\n",
      "Epoch [1/5], Loss: 0.2257\n",
      "Epoch [1/5], Valid Accuracy: 95.8600, Valid Loss: 0.1274\n",
      "Epoch [2/5], Loss: 0.0895\n",
      "Epoch [2/5], Valid Accuracy: 97.5300, Valid Loss: 0.0782\n",
      "Epoch [3/5], Loss: 0.0631\n",
      "Epoch [3/5], Valid Accuracy: 97.4400, Valid Loss: 0.0880\n",
      "Epoch [4/5], Loss: 0.0478\n",
      "Epoch [4/5], Valid Accuracy: 97.7000, Valid Loss: 0.0757\n",
      "Epoch [5/5], Loss: 0.0392\n",
      "Epoch [5/5], Valid Accuracy: 97.3800, Valid Loss: 0.0937\n",
      "Epoch [1/5], Loss: 0.2438\n",
      "Epoch [1/5], Valid Accuracy: 96.7600, Valid Loss: 0.1078\n",
      "Epoch [2/5], Loss: 0.0927\n",
      "Epoch [2/5], Valid Accuracy: 97.3800, Valid Loss: 0.0813\n",
      "Epoch [3/5], Loss: 0.0647\n",
      "Epoch [3/5], Valid Accuracy: 97.8300, Valid Loss: 0.0714\n",
      "Epoch [4/5], Loss: 0.0506\n",
      "Epoch [4/5], Valid Accuracy: 97.3600, Valid Loss: 0.0895\n",
      "Epoch [5/5], Loss: 0.0400\n",
      "Epoch [5/5], Valid Accuracy: 97.8500, Valid Loss: 0.0751\n",
      "Epoch [1/5], Loss: 0.2655\n",
      "Epoch [1/5], Valid Accuracy: 96.5000, Valid Loss: 0.1148\n",
      "Epoch [2/5], Loss: 0.0955\n",
      "Epoch [2/5], Valid Accuracy: 96.9800, Valid Loss: 0.0957\n",
      "Epoch [3/5], Loss: 0.0681\n",
      "Epoch [3/5], Valid Accuracy: 97.2900, Valid Loss: 0.0935\n",
      "Epoch [4/5], Loss: 0.0513\n",
      "Epoch [4/5], Valid Accuracy: 97.7000, Valid Loss: 0.0795\n",
      "Epoch [5/5], Loss: 0.0424\n",
      "Epoch [5/5], Valid Accuracy: 97.8100, Valid Loss: 0.0821\n",
      "Epoch [1/5], Loss: 0.2935\n",
      "Epoch [1/5], Valid Accuracy: 96.0600, Valid Loss: 0.1296\n",
      "Epoch [2/5], Loss: 0.0990\n",
      "Epoch [2/5], Valid Accuracy: 97.0600, Valid Loss: 0.0890\n",
      "Epoch [3/5], Loss: 0.0675\n",
      "Epoch [3/5], Valid Accuracy: 97.2800, Valid Loss: 0.0832\n",
      "Epoch [4/5], Loss: 0.0521\n",
      "Epoch [4/5], Valid Accuracy: 97.9300, Valid Loss: 0.0756\n",
      "Epoch [5/5], Loss: 0.0406\n",
      "Epoch [5/5], Valid Accuracy: 97.2800, Valid Loss: 0.0978\n",
      "Epoch [1/5], Loss: 0.3392\n",
      "Epoch [1/5], Valid Accuracy: 95.9400, Valid Loss: 0.1270\n",
      "Epoch [2/5], Loss: 0.1045\n",
      "Epoch [2/5], Valid Accuracy: 96.7300, Valid Loss: 0.1043\n",
      "Epoch [3/5], Loss: 0.0721\n",
      "Epoch [3/5], Valid Accuracy: 96.9300, Valid Loss: 0.0988\n",
      "Epoch [4/5], Loss: 0.0541\n",
      "Epoch [4/5], Valid Accuracy: 97.0700, Valid Loss: 0.0988\n",
      "Epoch [5/5], Loss: 0.0413\n",
      "Epoch [5/5], Valid Accuracy: 97.7400, Valid Loss: 0.0809\n",
      "Epoch [1/5], Loss: 0.4071\n",
      "Epoch [1/5], Valid Accuracy: 95.1600, Valid Loss: 0.1660\n",
      "Epoch [2/5], Loss: 0.1139\n",
      "Epoch [2/5], Valid Accuracy: 97.2000, Valid Loss: 0.0911\n",
      "Epoch [3/5], Loss: 0.0759\n",
      "Epoch [3/5], Valid Accuracy: 97.2500, Valid Loss: 0.0896\n",
      "Epoch [4/5], Loss: 0.0581\n",
      "Epoch [4/5], Valid Accuracy: 97.5900, Valid Loss: 0.0840\n",
      "Epoch [5/5], Loss: 0.0462\n",
      "Epoch [5/5], Valid Accuracy: 97.3800, Valid Loss: 0.0943\n",
      "Epoch [1/5], Loss: 0.5202\n",
      "Epoch [1/5], Valid Accuracy: 94.5400, Valid Loss: 0.1851\n",
      "Epoch [2/5], Loss: 0.1255\n",
      "Epoch [2/5], Valid Accuracy: 96.8000, Valid Loss: 0.1022\n",
      "Epoch [3/5], Loss: 0.0819\n",
      "Epoch [3/5], Valid Accuracy: 97.5700, Valid Loss: 0.0799\n",
      "Epoch [4/5], Loss: 0.0618\n",
      "Epoch [4/5], Valid Accuracy: 97.7600, Valid Loss: 0.0764\n",
      "Epoch [5/5], Loss: 0.0473\n",
      "Epoch [5/5], Valid Accuracy: 97.8700, Valid Loss: 0.0807\n",
      "Epoch [1/5], Loss: 0.8910\n",
      "Epoch [1/5], Valid Accuracy: 91.9800, Valid Loss: 0.2877\n",
      "Epoch [2/5], Loss: 0.1662\n",
      "Epoch [2/5], Valid Accuracy: 96.8000, Valid Loss: 0.1082\n",
      "Epoch [3/5], Loss: 0.0918\n",
      "Epoch [3/5], Valid Accuracy: 97.2000, Valid Loss: 0.0899\n",
      "Epoch [4/5], Loss: 0.0686\n",
      "Epoch [4/5], Valid Accuracy: 97.1500, Valid Loss: 0.0903\n",
      "Epoch [5/5], Loss: 0.0532\n",
      "Epoch [5/5], Valid Accuracy: 97.6300, Valid Loss: 0.0783\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>97.41</td>\n",
       "      <td>0.087582</td>\n",
       "      <td>0.039432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>97.38</td>\n",
       "      <td>0.093658</td>\n",
       "      <td>0.039167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>97.85</td>\n",
       "      <td>0.075085</td>\n",
       "      <td>0.040015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>97.81</td>\n",
       "      <td>0.082086</td>\n",
       "      <td>0.042351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>97.28</td>\n",
       "      <td>0.097819</td>\n",
       "      <td>0.040616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>97.74</td>\n",
       "      <td>0.080882</td>\n",
       "      <td>0.041318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>97.38</td>\n",
       "      <td>0.094288</td>\n",
       "      <td>0.046152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>97.87</td>\n",
       "      <td>0.080707</td>\n",
       "      <td>0.047316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>97.63</td>\n",
       "      <td>0.078330</td>\n",
       "      <td>0.053195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout  val_acc  val_loss  train_loss\n",
       "0      0.1    97.41  0.087582    0.039432\n",
       "1      0.2    97.38  0.093658    0.039167\n",
       "2      0.3    97.85  0.075085    0.040015\n",
       "3      0.4    97.81  0.082086    0.042351\n",
       "4      0.5    97.28  0.097819    0.040616\n",
       "5      0.6    97.74  0.080882    0.041318\n",
       "6      0.7    97.38  0.094288    0.046152\n",
       "7      0.8    97.87  0.080707    0.047316\n",
       "8      0.9    97.63  0.078330    0.053195"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropouts = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "rows = []\n",
    "for p in dropouts:\n",
    "    data = {}\n",
    "    net = get_model_v2(M=300, p=p)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, \n",
    "                                            num_epochs=5, model=net, \n",
    "                                            optimizer=optimizer)\n",
    "    data['dropout'] = p\n",
    "    data['val_acc'] = val_acc\n",
    "    data['val_loss'] = val_loss\n",
    "    data['train_loss'] = train_loss\n",
    "    rows.append(data)\n",
    "        \n",
    "        \n",
    "df_4 = pd.DataFrame(rows) \n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
